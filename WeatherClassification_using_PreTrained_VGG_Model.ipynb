{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93cac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load useful packages\n",
    "!pip install wget\n",
    "from random import sample\n",
    "\n",
    "import keras\n",
    "# import os.path\n",
    "from os import path\n",
    "import h5py\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import wget\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import DenseNet169\n",
    "from tensorflow.keras.applications.densenet import DenseNet201\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, losses\n",
    "from tensorflow.keras.preprocessing import image        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b4190",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('cloudy','rain','shine','sunrise')\n",
    "data_path = 'https://raw.githubusercontent.com/Shujaat123/Weather_Classification/master/dataset/'\n",
    "\n",
    "flist = []\n",
    "for fname in classes:\n",
    "  filename = 'WeatherClassificationDB_'+fname+'.mat'\n",
    "  if(path.exists(filename)):\n",
    "    !rm $filename\n",
    "    print('existing file:', filename, ' has been deleted')\n",
    "  print('downloading latest version of file:', filename)\n",
    "  file_path = data_path + filename\n",
    "  wget.download(file_path, filename)\n",
    "  print('DONE')\n",
    "  flist.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56f8819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading input and labels\n",
    "cloudy_imgs = np.array(h5py.File(flist[0], 'r')['images']['input'])\n",
    "cloudy_labels = np.array(h5py.File(flist[0], 'r')['images']['label'])\n",
    "\n",
    "rain_imgs = np.array(h5py.File(flist[1], 'r')['images']['input'])\n",
    "rain_labels = np.array(h5py.File(flist[1], 'r')['images']['label'])\n",
    "\n",
    "shine_imgs = np.array(h5py.File(flist[2], 'r')['images']['input'])\n",
    "shine_labels = np.array(h5py.File(flist[2], 'r')['images']['label'])\n",
    "\n",
    "sunrise_imgs = np.array(h5py.File(flist[3], 'r')['images']['input'])\n",
    "sunrise_labels = np.array(h5py.File(flist[3], 'r')['images']['label'])\n",
    "\n",
    "#Setting labels from 0 to 3 (Intially: 1 to 4)\n",
    "super_threshold_indices_CL = cloudy_labels > 0\n",
    "cloudy_labels[super_threshold_indices_CL] = 0\n",
    "\n",
    "super_threshold_indices_RA = rain_labels > 0\n",
    "rain_labels[super_threshold_indices_RA] = 1\n",
    "\n",
    "super_threshold_indices_SH = shine_labels > 0\n",
    "shine_labels[super_threshold_indices_SH] = 2\n",
    "\n",
    "super_threshold_indices_SUN = sunrise_labels > 0\n",
    "sunrise_labels[super_threshold_indices_SUN] = 3\n",
    "\n",
    "InputImages = np.concatenate((cloudy_imgs,rain_imgs,shine_imgs,sunrise_imgs), axis = 0)\n",
    "InputImages = InputImages/InputImages.max()\n",
    "ClassLabels = np.concatenate((cloudy_labels,rain_labels,shine_labels,sunrise_labels), axis = 0)\n",
    "\n",
    "print(cloudy_imgs.shape)\n",
    "print(rain_imgs.shape)\n",
    "print(shine_imgs.shape)\n",
    "print(sunrise_imgs.shape)\n",
    "print(InputImages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c712ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = 0.8\n",
    "valid_percent = 0.1\n",
    "num_CL_Tr = np.round(len(cloudy_imgs)*train_percent).__int__()\n",
    "num_RA_Tr = np.round(len(rain_imgs)*train_percent).__int__()\n",
    "num_SH_Tr = np.round(len(shine_imgs)*train_percent).__int__()\n",
    "num_SUN_Tr = np.round(len(sunrise_imgs)*train_percent).__int__()\n",
    "\n",
    "num_CL_Te = np.round(len(cloudy_imgs)*valid_percent).__int__()\n",
    "num_RA_Te = np.round(len(rain_imgs)*valid_percent).__int__()\n",
    "num_SH_Te = np.round(len(shine_imgs)*valid_percent).__int__()\n",
    "num_SUN_Te = np.round(len(sunrise_imgs)*valid_percent).__int__()\n",
    "\n",
    "print('Number of Training samples for cloudy images:',num_CL_Tr)\n",
    "print('Number of Training samples for rainy images:',num_RA_Tr)\n",
    "print('Number of Training samples for shiny images:',num_SH_Tr)\n",
    "print('Number of Training samples for sunny images:',num_SUN_Tr)\n",
    "CL_list = list(range(0,len(cloudy_imgs)))\n",
    "RA_list = list(range(0,len(rain_imgs)))\n",
    "SH_list = list(range(0,len(shine_imgs)))\n",
    "SUN_list = list(range(0,len(sunrise_imgs)))\n",
    "total_list  = CL_list+RA_list+SH_list+SUN_list\n",
    "\n",
    "CL_Train = sample(CL_list,num_CL_Tr)\n",
    "RA_Train = sample(RA_list,num_RA_Tr)\n",
    "SH_Train = sample(SH_list,num_SH_Tr)\n",
    "SUN_Train = sample(SUN_list,num_SUN_Tr)\n",
    "train_list = CL_Train + RA_Train + SH_Train + SUN_Train\n",
    "\n",
    "CL_Labels = cloudy_labels[CL_Train]\n",
    "RA_Labels = rain_labels[RA_Train]\n",
    "SH_Labels = shine_labels[SH_Train]\n",
    "SUN_Labels = sunrise_labels[SUN_Train]\n",
    "Label_train = np.concatenate((CL_Labels,RA_Labels,SH_Labels,SUN_Labels), axis = 0)\n",
    "\n",
    "\n",
    "print('Number of Testing samples for cloudy images:',num_CL_Te)\n",
    "print('Number of Testing samples for rainy images:',num_RA_Te)\n",
    "print('Number of Testing samples for shiny images:',num_SH_Te)\n",
    "print('Number of Testing samples for sunny images:',num_SUN_Te)\n",
    "\n",
    "CL_Test = sample(set(CL_list) - set(CL_Train), num_CL_Te)\n",
    "RA_Test = sample(set(RA_list) - set(RA_Train), num_RA_Te)\n",
    "SH_Test = sample(set(SH_list) - set(SH_Train), num_SH_Te)\n",
    "SUN_Test = sample(set(SUN_list) - set(SUN_Train), num_SUN_Te)\n",
    "test_list = CL_Test + RA_Test + SH_Test + SUN_Test\n",
    "\n",
    "CL_Labels_te = cloudy_labels[CL_Test]\n",
    "RA_Labels_te = rain_labels[RA_Test]\n",
    "SH_Labels_te = shine_labels[SH_Test]\n",
    "SUN_Labels_te = sunrise_labels[SUN_Test]\n",
    "Label_test = np.concatenate((CL_Labels_te,RA_Labels_te,SH_Labels_te,SUN_Labels_te), axis = 0)\n",
    "\n",
    "CL_val = list(set(CL_list) - set(CL_Train) - set(CL_Test))\n",
    "RA_val = list(set(RA_list) - set(RA_Train) - set(RA_Test))\n",
    "SH_val = list(set(SH_list) - set(SH_Train) - set(SH_Test))\n",
    "SUN_val = list(set(SUN_list) - set(SUN_Train) - set(SUN_Test))\n",
    "val_list = CL_val+RA_val+SH_val+SUN_val\n",
    "\n",
    "CL_Labels_val = cloudy_labels[CL_val]\n",
    "RA_Labels_val = rain_labels[RA_val]\n",
    "SH_Labels_val = shine_labels[SH_val]\n",
    "SUN_Labels_val = sunrise_labels[SUN_val]\n",
    "Label_val = np.concatenate((CL_Labels_val,RA_Labels_val,SH_Labels_val,SUN_Labels_val), axis = 0)\n",
    "\n",
    "print('Number of Validation samples for cloudy images:',len(CL_Labels_val))\n",
    "print('Number of Validation samples for rainy images:',len(RA_Labels_val))\n",
    "print('Number of Validation samples for shiny images:',len(SH_Labels_val))\n",
    "print('Number of Validation samples for sunny images:',len(SUN_Labels_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49efcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Labels to categorical (One hot coding)\n",
    "Label_train = np.squeeze(Label_train)\n",
    "Label_train = to_categorical(Label_train)\n",
    "print(Label_train.shape)\n",
    "\n",
    "Label_test = np.squeeze(Label_test)\n",
    "Label_test = to_categorical(Label_test)\n",
    "print(Label_test.shape)\n",
    "\n",
    "Label_val = np.squeeze(Label_val)\n",
    "Label_val = to_categorical(Label_val)\n",
    "print(Label_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360459b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate train, test and validation Input images\n",
    "Input_train = np.concatenate((cloudy_imgs[CL_Train],rain_imgs[RA_Train],shine_imgs[SH_Train],sunrise_imgs[SUN_Train]), axis = 0)\n",
    "print(Input_train.shape)\n",
    "\n",
    "Input_test = np.concatenate((cloudy_imgs[CL_Test],rain_imgs[RA_Test],shine_imgs[SH_Test],sunrise_imgs[SUN_Test]), axis = 0)\n",
    "print(Input_test.shape)\n",
    "\n",
    "Input_val = np.concatenate((cloudy_imgs[CL_val],rain_imgs[RA_val],shine_imgs[SH_val],sunrise_imgs[SUN_val]), axis = 0)\n",
    "print(Input_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b333c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization between 0 and 1 \n",
    "Input_train, Input_test, Input_val = Input_train / 255.0, Input_test / 255.0, Input_val/ 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf31dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Trained Model VGG\n",
    "# def new_model():\n",
    "base_model = VGG16(include_top=False, weights = None, input_shape=(256,256,3), pooling='None')\n",
    "for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "  # add new classifier layers\n",
    "flat1 = Flatten()(base_model.layers[-1].output)\n",
    "flat1 = BatchNormalization()(flat1)\n",
    "flat1 = Dropout(0.5)(flat1)\n",
    "class1 = Dense(10, activation='relu')(flat1)\n",
    "class2 = Dense(10, activation='relu')(class1)\n",
    "output = Dense(4, activation='softmax')(class2)\n",
    "  # define new model\n",
    "Arch_pre = Model(inputs=base_model.inputs, outputs=output)\n",
    "  # summarize\n",
    "Arch_pre.summary()\n",
    "opt = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "Arch_pre.compile(loss='categorical_crossentropy',metrics = ['accuracy'],optimizer=opt)\n",
    "#     return my_model\n",
    "\n",
    "# Arch_pre = new_model() \n",
    "len(base_model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2362e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the best model \n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, mode='min')\n",
    "\n",
    "checkpoint = ModelCheckpoint('models\\\\modelweather-best.h5',\n",
    "                                  verbose=0, monitor='val_loss',save_best_only=True, mode='auto')\n",
    "\n",
    "Arch_pre.fit(Input_train, Label_train,\n",
    "                epochs=200,\n",
    "                batch_size=132,\n",
    "                shuffle=True,\n",
    "                validation_data=(Input_val, Label_val),\n",
    "                callbacks = [es, checkpoint]\n",
    "                )\n",
    "\n",
    "del Arch_pre  # deletes the existing model\n",
    "Arch_pre = load_model('models\\\\modelweather-best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f824f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance Evaluation on test data\n",
    "Predicted_test =  Arch_pre.evaluate(Input_test,Label_test)\n",
    "Predicted_test =  np.clip(Predicted_test, 0., 1.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
